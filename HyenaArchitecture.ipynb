{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO+HeI9q3w53xM3ygoxyySH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**The Hyena Architecture: A Transformer Without Attention**"],"metadata":{"id":"ss6sqO0byhdu"}},{"cell_type":"markdown","source":["An innovation in deep learning has been the Transformer architecture. However, the self-attention mechanism's computational cost, which scales quadratically (O(n^2)) with sequence length, is a major bottleneck. The Hyena Hierarchy architecture, introduced in the 2023 paper \"Hyena Hierarchy: Towards Larger Convolutional Language Models\", presents a compelling alternative.\n","\n","Hyena replaces the attention mechanism with a more efficient operator based on long convolutions, demonstrating comparable performance while offering significant speed and memory advantages for long sequences.\n","\n","The core ideas are:\n","\n","1) Long Convolutions: A filter that extends across the entire sequence to model long-range dependencies.\n","\n","2) Implicitly Parameterized Filters: Instead of learning a giant filter directly, a smaller neural network generates its weights on-the-fly.\n","\n","3) Data-Controlled Gating: An input-dependent mechanism modulates the convolution's output, mimicking attention's dynamic nature.\n","\n","---------------------------------------------------------------------------"],"metadata":{"id":"oayHhUP3yuKw"}},{"cell_type":"markdown","source":["**Part 1: Hyena from Scratch with NumPy**"],"metadata":{"id":"Jj9GjwZtzG68"}},{"cell_type":"markdown","source":["Building a model from scratch without a framework like PyTorch means we handle every operation ourselves. This approach is excellent for me to understand the raw mechanics of the forward pass. A full training implementation would require manually coding the backward pass (backpropagation) for each function.\n","\n"],"metadata":{"id":"4RnSE3qgzM9V"}},{"cell_type":"markdown","source":["*A) Basic Building Blocks (NumPy)*\n","\n","*First, we need our own versions of standard neural network layers using NumPy.*"],"metadata":{"id":"xDDU4pc9zZjE"}},{"cell_type":"code","source":["import numpy as np\n","\n","class Linear:\n","    \"\"\"A fully connected layer.\"\"\"\n","    def __init__(self, in_features, out_features):\n","        # Initialize weights with a common scheme (He initialization)\n","        self.weights = np.random.randn(in_features, out_features) * np.sqrt(2. / in_features)\n","        self.biases = np.zeros(out_features)\n","\n","    def forward(self, x):\n","        # Standard matrix multiplication: X @ W + b\n","        return x @ self.weights + self.biases\n","\n","class GELU:\n","    \"\"\"Gaussian Error Linear Unit activation function.\"\"\"\n","    def forward(self, x):\n","        # An approximation of the GELU activation\n","        return 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x**3)))\n","\n","class LayerNorm:\n","    \"\"\"Layer normalization.\"\"\"\n","    def __init__(self, d_model, eps=1e-5):\n","        self.d_model = d_model\n","        self.eps = eps\n","        self.gamma = np.ones(d_model) # Learnable scale\n","        self.beta = np.zeros(d_model)  # Learnable shift\n","\n","    def forward(self, x):\n","        mean = np.mean(x, axis=-1, keepdims=True)\n","        var = np.var(x, axis=-1, keepdims=True)\n","        x_norm = (x - mean) / np.sqrt(var + self.eps)\n","        return self.gamma * x_norm + self.beta\n","\n","class Conv1d:\n","    \"\"\"A simple 1D depth-wise convolution.\"\"\"\n","    def __init__(self, d_model, kernel_size, padding=1):\n","        # For a depth-wise conv, each input channel has its own filter\n","        self.kernel = np.random.randn(d_model, 1, kernel_size)\n","        self.padding = padding\n","\n","    def forward(self, x):\n","        # x shape: (B, L, D) -> transpose to (B, D, L) for convolution\n","        x = x.transpose(0, 2, 1)\n","        B, D, L = x.shape\n","\n","        # Apply padding\n","        x_padded = np.pad(x, ((0, 0), (0, 0), (self.padding, self.padding)), 'constant')\n","\n","        output = np.zeros_like(x)\n","        # Manually perform the convolution for each channel\n","        for d in range(D):\n","            for l in range(L):\n","                output[:, d, l] = np.sum(x_padded[:, d, l:l+self.kernel.shape[2]] * self.kernel[d, 0, :], axis=1)\n","\n","        return output.transpose(0, 2, 1) # Transpose back to (B, L, D)"],"metadata":{"id":"g8ESHl61zhNr","executionInfo":{"status":"ok","timestamp":1759122266278,"user_tz":-330,"elapsed":79,"user":{"displayName":"Arnav Gawade","userId":"11577027889609509874"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["*What is this?*\n","\n","This block defines the fundamental layers of a neural network (Linear, GELU, LayerNorm, Conv1d) from scratch using only NumPy. Each class initializes its own learnable parameters (like weights and biases) and implements a forward method to perform its specific mathematical operation on input data.\n","\n","*Why do we do this?*\n","\n","\n","To build a neural network without a framework like PyTorch, we must first create our own tools. This code demystifies what a \"layer\" actually is: a self-contained object that holds state (parameters) and performs a specific transformation (e.g., matrix multiplication). This is the foundation upon which the more complex Hyena architecture is built, providing a clear view of the underlying mathematics.\n","\n","--------------------------------------------------------------"],"metadata":{"id":"o0s2fMsp1Fam"}},{"cell_type":"markdown","source":["*B) The Core Hyena Operator (NumPy)*\n","\n","*Now for the main event. We'll implement the HyenaOperator using our NumPy building blocks and NumPy's FFT library.*"],"metadata":{"id":"4H-uyoBjzlH8"}},{"cell_type":"code","source":["class PositionalEmbedding:\n","    \"\"\"Generates learnable positional embeddings for the filter.\"\"\"\n","    def __init__(self, emb_dim, seq_len):\n","        self.embedding = np.random.randn(emb_dim, seq_len)\n","\n","    def forward(self, L):\n","        return self.embedding[:, :L]\n","\n","class HyenaOperator:\n","    \"\"\"The Hyena operator from scratch in NumPy.\"\"\"\n","    def __init__(self, d_model, max_seq_len, filter_order=64):\n","        self.d_model = d_model\n","        self.max_seq_len = max_seq_len\n","\n","        # Positional embeddings for the filter\n","        self.filter_pos_emb = PositionalEmbedding(filter_order, max_seq_len)\n","\n","        # Small FFN to generate the filter\n","        self.filter_net = [\n","            Linear(filter_order, d_model),\n","            GELU(),\n","            Linear(d_model, d_model)\n","        ]\n","\n","        # Input/output projections and short convolution\n","        self.in_proj = Linear(d_model, 2 * d_model)\n","        self.out_proj = Linear(d_model, d_model)\n","        self.short_conv = Conv1d(d_model, kernel_size=3, padding=1)\n","\n","    def forward(self, x):\n","        B, L, D = x.shape\n","\n","        # --- 1. Generate the long convolutional filter ---\n","        pos_emb = self.filter_pos_emb.forward(L).T # Shape (L, filter_order)\n","\n","        # Pass through the filter network\n","        k = pos_emb\n","        for layer in self.filter_net:\n","            k = layer.forward(k) # k shape: (L, D)\n","\n","        # --- 2. Project the input ---\n","        projected_x = self.in_proj.forward(x)\n","        v, gate_res = np.split(projected_x, 2, axis=-1) # Each is (B, L, D)\n","\n","        # --- 3. FFT Convolution ---\n","        fft_len = 2 * L\n","\n","        # Apply FFT. NumPy's rfft expects the last axis to be the one transformed.\n","        v_fft = np.fft.rfft(v, n=fft_len, axis=1)   # Transform along L\n","        k_fft = np.fft.rfft(k, n=fft_len, axis=0)   # Transform along L\n","\n","        # Multiply in frequency domain. Add a batch dimension to k_fft.\n","        y_fft = v_fft * k_fft[np.newaxis, :, :]\n","\n","        # Apply inverse FFT and crop\n","        y = np.fft.irfft(y_fft, n=fft_len, axis=1)[:, :L, :] # Crop L dim\n","\n","        # --- 4. Apply Gating Mechanism ---\n","        short_conv_out = self.short_conv.forward(x)\n","\n","        y = y * gate_res\n","        y = y + short_conv_out * (1 - gate_res)\n","\n","        output = self.out_proj.forward(y)\n","        return output"],"metadata":{"id":"fcf1gIU_ztTi","executionInfo":{"status":"ok","timestamp":1759122266324,"user_tz":-330,"elapsed":5,"user":{"displayName":"Arnav Gawade","userId":"11577027889609509874"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["*What is this?*\n","\n","This is the heart of the Hyena model. The HyenaOperator defines the entire process of replacing self-attention. It uses a PositionalEmbedding and a small feed-forward network (filter_net) to generate a long convolutional filter (k) on-the-fly. It then uses the Fast Fourier Transform (FFT) to efficiently convolve this filter with the input sequence (v). Finally, it combines this result with a short-range convolution using a gating mechanism.\n","\n","*Why do we do this?*\n","\n","This entire operator is designed to solve the quadratic complexity problem of self-attention.\n","\n","- Implicit Filter Generation: Instead of learning a massive filter of size (seq_len, d_model), we learn a tiny network that generates it. This is memory efficient.\n","\n","- FFT Convolution: Convolving in the time domain is slow (O(L\n","2\n"," )). By transforming the signals to the frequency domain, convolution becomes a simple element-wise multiplication, which is incredibly fast (O(LlogL)). This is the key to Hyena's efficiency.\n","\n","- Gating: The gating mechanism allows the operator to dynamically decide whether to focus on long-range patterns (from the FFT convolution) or local patterns (from the short convolution) for each token, making it adaptive like attention.\n","\n","-------------------------------------------------------------------------"],"metadata":{"id":"A_AOz0Ve1pTF"}},{"cell_type":"markdown","source":["*C) Assembling the Full Model (NumPy)*\n","\n","*Finally, we stack the HyenaLayers to create the full language model.*"],"metadata":{"id":"RjW_ei0_zxU3"}},{"cell_type":"code","source":["class HyenaLayer:\n","    \"\"\"A single Hyena layer with normalization and FFN.\"\"\"\n","    def __init__(self, d_model, max_seq_len):\n","        self.hyena = HyenaOperator(d_model, max_seq_len)\n","        self.ffn = [\n","            Linear(d_model, 4 * d_model),\n","            GELU(),\n","            Linear(4 * d_model, d_model)\n","        ]\n","        self.norm1 = LayerNorm(d_model)\n","        self.norm2 = LayerNorm(d_model)\n","\n","    def forward(self, x):\n","        x = x + self.hyena.forward(self.norm1.forward(x))\n","\n","        ffn_out = self.norm2.forward(x)\n","        for layer in self.ffn:\n","            ffn_out = layer.forward(ffn_out)\n","\n","        x = x + ffn_out\n","        return x\n","\n","class HyenaLanguageModel:\n","    \"\"\"The full language model built with NumPy.\"\"\"\n","    def __init__(self, vocab_size, d_model, n_layers, max_seq_len):\n","        self.token_embedding_table = np.random.randn(vocab_size, d_model)\n","        self.pos_embedding_table = np.random.randn(max_seq_len, d_model)\n","        self.layers = [HyenaLayer(d_model, max_seq_len) for _ in range(n_layers)]\n","        self.output_head = Linear(d_model, vocab_size)\n","\n","    def forward(self, idx):\n","        B, L = idx.shape\n","        tok_emb = self.token_embedding_table[idx] # (B, L, D)\n","        pos_emb = self.pos_embedding_table[:L, :]   # (L, D)\n","        x = tok_emb + pos_emb\n","\n","        for layer in self.layers:\n","            x = layer.forward(x)\n","\n","        logits = self.output_head.forward(x)\n","        return logits\n","\n","# --- Example Usage (NumPy) ---\n","VOCAB_SIZE_NP = 1000\n","D_MODEL_NP = 64\n","N_LAYERS_NP = 2\n","MAX_SEQ_LEN_NP = 256\n","\n","model_np = HyenaLanguageModel(VOCAB_SIZE_NP, D_MODEL_NP, N_LAYERS_NP, MAX_SEQ_LEN_NP)\n","input_tokens_np = np.random.randint(0, VOCAB_SIZE_NP, size=(4, 128))\n","output_logits_np = model_np.forward(input_tokens_np)\n","\n","print(\"--- NumPy Implementation ---\")\n","print(f\"Input shape: {input_tokens_np.shape}\")\n","print(f\"Output logits shape: {output_logits_np.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dVj7J9Ecz52H","executionInfo":{"status":"ok","timestamp":1759122266697,"user_tz":-330,"elapsed":375,"user":{"displayName":"Arnav Gawade","userId":"11577027889609509874"}},"outputId":"cf0324ea-22a3-491c-f2ff-93b482d773c7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--- NumPy Implementation ---\n","Input shape: (4, 128)\n","Output logits shape: (4, 128, 1000)\n"]}]},{"cell_type":"markdown","source":["*What is this?*\n","\n","This block assembles the HyenaOperator into a complete, deep language model. The HyenaLayer follows the standard Transformer block structure: it combines the main operator (HyenaOperator) with a simple feed-forward network (ffn), using residual connections and layer normalization around each. The HyenaLanguageModel class then takes token IDs as input, converts them to embeddings, and stacks multiple HyenaLayers to produce the final output logits.\n","\n","*Why do we do this?*\n","\n","A single layer can only learn simple patterns. Depth is crucial for a model's performance. By stacking layers, the model creates a hierarchy of representations. Early layers might capture simple local features (like word pairings), while deeper layers can combine these to understand more abstract concepts like sentence structure, context, and semantics. The residual connections are vital for training deep networks by preventing the vanishing gradient problem, ensuring that information flows smoothly through all the layers.\n","\n","----------------------------------------------------------------"],"metadata":{"id":"TOCylO_k2Oeo"}},{"cell_type":"markdown","source":["**Part 2: Hyena with PyTorch**"],"metadata":{"id":"hNDvb-7n0ASo"}},{"cell_type":"markdown","source":["Using a framework like PyTorch abstracts away the manual gradient calculations and provides optimized, pre-built layers. This makes building, training, and deploying models vastly more practical. This code is fully functional and trainable."],"metadata":{"id":"F-iGXSQP0CP4"}},{"cell_type":"markdown","source":["*The Hyena Operator and Model (PyTorch)*\n","\n","*Here we define all the necessary components using PyTorch's nn.Module.*"],"metadata":{"id":"wSjzICNq0Lh1"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.fft import rfft, irfft\n","\n","class PositionalEmbedding(nn.Module):\n","    def __init__(self, emb_dim: int, seq_len: int):\n","        super().__init__()\n","        self.embedding = nn.Parameter(torch.randn(emb_dim, seq_len))\n","\n","    def forward(self, L: int):\n","        return self.embedding[:, :L]\n","\n","class HyenaOperator(nn.Module):\n","    def __init__(self, d_model: int, max_seq_len: int, filter_order: int = 64):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.max_seq_len = max_seq_len\n","        self.filter_pos_emb = PositionalEmbedding(filter_order, max_seq_len)\n","\n","        self.filter_net = nn.Sequential(\n","            nn.Linear(filter_order, d_model),\n","            nn.GELU(),\n","            nn.Linear(d_model, d_model)\n","        )\n","\n","        self.in_proj = nn.Linear(d_model, 2 * d_model)\n","        self.out_proj = nn.Linear(d_model, d_model)\n","\n","        self.short_conv = nn.Conv1d(\n","            in_channels=d_model,\n","            out_channels=d_model,\n","            kernel_size=3,\n","            padding=1,\n","            groups=d_model\n","        )\n","\n","    def forward(self, x):\n","        B, L, D = x.shape\n","\n","        # --- 1. Generate the long convolutional filter ---\n","        pos_emb = self.filter_pos_emb(L)\n","        k = self.filter_net(pos_emb.transpose(0, 1)) # Shape: (L, D)\n","\n","        # --- 2. Project the input sequence ---\n","        v, gate_res = self.in_proj(x).split(self.d_model, dim=-1)\n","\n","        # --- 3. Perform FFT-based convolution ---\n","        fft_len = 2 * L\n","        v_fft = rfft(v.transpose(1, 2), n=fft_len)\n","        k_fft = rfft(k.transpose(0, 1).unsqueeze(0), n=fft_len)\n","        y_fft = v_fft * k_fft\n","        y = irfft(y_fft, n=fft_len)[:, :, :L].transpose(1, 2)\n","\n","        # --- 4. Apply the gating mechanism ---\n","        short_conv_out = self.short_conv(x.transpose(1, 2)).transpose(1, 2)\n","        y = y * gate_res\n","        y = y + short_conv_out * (1 - gate_res)\n","\n","        output = self.out_proj(y)\n","        return output\n","\n","class HyenaLayer(nn.Module):\n","    def __init__(self, d_model: int, max_seq_len: int):\n","        super().__init__()\n","        self.hyena = HyenaOperator(d_model, max_seq_len)\n","        self.ffn = nn.Sequential(\n","            nn.Linear(d_model, 4 * d_model),\n","            nn.GELU(),\n","            nn.Linear(4 * d_model, d_model)\n","        )\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","\n","    def forward(self, x):\n","        x = x + self.hyena(self.norm1(x))\n","        x = x + self.ffn(self.norm2(x))\n","        return x\n","\n","class HyenaLanguageModel(nn.Module):\n","    def __init__(self, vocab_size: int, d_model: int, n_layers: int, max_seq_len: int):\n","        super().__init__()\n","        self.token_embedding = nn.Embedding(vocab_size, d_model)\n","        self.pos_embedding = nn.Parameter(torch.randn(1, max_seq_len, d_model))\n","        self.layers = nn.ModuleList([HyenaLayer(d_model, max_seq_len) for _ in range(n_layers)])\n","        self.output_head = nn.Linear(d_model, vocab_size)\n","\n","    def forward(self, x):\n","        B, L = x.shape\n","        x = self.token_embedding(x)\n","        x = x + self.pos_embedding[:, :L, :]\n","\n","        for layer in self.layers:\n","            x = layer(x)\n","\n","        logits = self.output_head(x)\n","        return logits\n","\n","# --- Example Usage (PyTorch) ---\n","VOCAB_SIZE_PT = 1000\n","D_MODEL_PT = 64\n","N_LAYERS_PT = 2\n","MAX_SEQ_LEN_PT = 256\n","\n","model_pt = HyenaLanguageModel(VOCAB_SIZE_PT, D_MODEL_PT, N_LAYERS_PT, MAX_SEQ_LEN_PT)\n","input_tokens_pt = torch.randint(0, VOCAB_SIZE_PT, (4, 128))\n","output_logits_pt = model_pt(input_tokens_pt)\n","\n","print(\"\\n\" + \"--- PyTorch Implementation ---\")\n","print(f\"Model created with {sum(p.numel() for p in model_pt.parameters()):,} parameters.\")\n","print(f\"Input shape: {input_tokens_pt.shape}\")\n","print(f\"Output logits shape: {output_logits_pt.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cn2ISPCk0Ssc","executionInfo":{"status":"ok","timestamp":1759122278851,"user_tz":-330,"elapsed":12148,"user":{"displayName":"Arnav Gawade","userId":"11577027889609509874"}},"outputId":"34d01cd0-e82b-40a0-be97-f3b5528fc6ff"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- PyTorch Implementation ---\n","Model created with 286,952 parameters.\n","Input shape: torch.Size([4, 128])\n","Output logits shape: torch.Size([4, 128, 1000])\n"]}]},{"cell_type":"markdown","source":["*What is this?*\n","\n","This is the practical, trainable implementation of the complete Hyena architecture using PyTorch. It mirrors the structure of the NumPy version but uses PyTorch's nn.Module as the base for all classes. This provides several key features for free:\n","\n","- Automatic Parameter Tracking: Any nn.Parameter or submodule is automatically registered.\n","\n","- Optimized Layers: nn.Linear, nn.Conv1d, etc., are highly optimized C++ or CUDA kernels.\n","\n","- Automatic Differentiation: PyTorch's autograd engine automatically tracks all operations in the forward pass to compute gradients for the backward pass, which is essential for training.\n","\n","*Why do we do this?*\n","\n","While the NumPy version is invaluable for understanding the mechanics, it's not practical for real-world use. The PyTorch version is for actually building and training models. It abstracts away the complex, error-prone process of manual backpropagation and provides a robust, high-performance toolkit. This allows researchers and engineers to focus on designing the model architecture (the \"what\") without having to reinvent the underlying machinery of training and optimization (the \"how\"). It also makes it trivial to run the model on a GPU for massive speedups.\n","\n","--------------------------------------------------------------------------"],"metadata":{"id":"xFaIBHsz2e6K"}},{"cell_type":"markdown","source":["**Part 3: Reference**\n","\n","The concepts and architecture are based on the original research paper. For a deeper dive, it's a highly recommended read.\n","\n","Paper Title: \"Hyena Hierarchy: Towards Larger Convolutional Language Models\"\n","\n","arXiv Link: https://arxiv.org/abs/2302.10866**"],"metadata":{"id":"92aJDZrs0VMj"}}]}